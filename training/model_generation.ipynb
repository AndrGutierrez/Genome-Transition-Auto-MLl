{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T23:49:06.702147Z",
     "start_time": "2025-03-24T23:49:06.693608Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T23:47:01.338981Z",
     "start_time": "2025-03-24T23:47:01.322136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove models folder if it exists\n",
    "import shutil\n",
    "shutil.rmtree(\"../models\", ignore_errors=True)"
   ],
   "id": "6c0e6a43ad138192",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T23:47:01.350659Z",
     "start_time": "2025-03-24T23:47:01.345119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(true_data, counter_files, max_index):\n",
    "    combined_data = {}\n",
    "    # Define the column names to keep.\n",
    "    cols = [f\"B{i}\" for i in range(1, max_index + 1)]\n",
    "\n",
    "    # Process the true data: retain only the B columns and add the true label.\n",
    "    true_data['label'] = \"true\"\n",
    "    true_data = true_data[cols + [\"label\"]]\n",
    "\n",
    "    for key, path in counter_files.items():\n",
    "        # Load the counter example file.\n",
    "        df_counter = pd.read_csv(path)\n",
    "        # Retain only the B columns and add the false label.\n",
    "        df_counter['label'] = \"false\"\n",
    "        df_counter = df_counter[cols + [\"label\"]]\n",
    "        # Combine the true data with this counter example.\n",
    "        combined = pd.concat([true_data, df_counter], ignore_index=True)\n",
    "        combined_data[key] = combined\n",
    "\n",
    "    return combined_data"
   ],
   "id": "1ba82cefa1f193c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T23:47:01.653355Z",
     "start_time": "2025-03-24T23:47:01.645227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "presets = ['good_quality', 'optimize_for_deployment']\n",
    "\n",
    "def generateModels(combined_data, prefix, max_index, time_limit=180):\n",
    "    results = {}\n",
    "    # Define the feature columns\n",
    "    feature_cols = [f\"B{i}\" for i in range(1, max_index + 1)]\n",
    "\n",
    "    for key, df in combined_data.items():\n",
    "        # Split data into features and label.\n",
    "        X = df[feature_cols]\n",
    "        y = df[\"label\"]\n",
    "\n",
    "        # Train-test split: 70% train, 30% test.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        train_data = pd.concat([X_train, y_train], axis=1)\n",
    "        test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "        # Define an output folder for saving models for this dataset variant.\n",
    "        output_folder = f\"../models/{prefix}/{key}\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Train the model using AutoGluon.\n",
    "        predictor = TabularPredictor(label=\"label\", path=output_folder, eval_metric='f1').fit(train_data, presets=presets, time_limit=time_limit)\n",
    "\n",
    "        # Evaluate the model on the test data.\n",
    "        leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "        results[key] = leaderboard\n",
    "\n",
    "        print(f\"Results for {key}:\")\n",
    "        print(leaderboard)\n",
    "\n",
    "    # Create results folder and save leaderboards.\n",
    "    results_folder = f\"../models/{prefix}/results\"\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "    for key, result in results.items():\n",
    "        result.to_csv(os.path.join(results_folder, f\"{key}_leaderboard.csv\"), index=False)"
   ],
   "id": "81f67c0ce624347c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T00:22:43.423448Z",
     "start_time": "2025-03-24T23:49:10.817202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "true_file = \"../data/ei/data_ei.csv\"\n",
    "ei_true_data = pd.read_csv(true_file)\n",
    "\n",
    "# List of counter example files for the EI zone\n",
    "counter_files = {\n",
    "    \"ei_random\": \"../data/ei/data_ei_random.csv\",\n",
    "    \"ei_ez_counter\": \"../data/ei/data_ez_counter_example.csv\",\n",
    "    \"ei_ie_counter\": \"../data/ei/data_ie_counter_example.csv\",\n",
    "    \"ei_ze_counter\": \"../data/ei/data_ze_counter_example.csv\",\n",
    "    \"sample_combined_counter\": \"../data/ei/data_sample_combined.csv\"\n",
    "}\n",
    "\n",
    "# For EI zone, our CSV files have columns B1 to B12.\n",
    "combined_data = prepare_data(ei_true_data, counter_files, max_index=12)\n",
    "\n",
    "# Dictionary to store the combined DataFrames and later model results\n",
    "generateModels(combined_data, 'ei', 12, time_limit=900)"
   ],
   "id": "2d84d45e4f7d2f32",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../models/ei/ei_ze_counter\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       1.85 GB / 15.35 GB (12.1%)\n",
      "Disk Space Avail:   552.81 GB / 731.50 GB (75.6%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "\t\tContext path: \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestGini_BAG_L2_FULL       0.985933   0.983573          f1        1.096663            NaN  36.805295                 0.108623                0.549298           1.946152            2       True          9\n",
      "1     ExtraTreesGini_BAG_L2_FULL       0.985738   0.983947          f1        1.121251            NaN  36.139115                 0.133210                0.995780           1.279972            2       True         12\n",
      "2     ExtraTreesEntr_BAG_L2_FULL       0.985738   0.983920          f1        1.128706            NaN  35.905437                 0.140665                0.556672           1.046294            2       True         13\n",
      "3   RandomForestEntr_BAG_L2_FULL       0.985313   0.983728          f1        1.094030            NaN  36.658521                 0.105989                0.506160           1.799378            2       True         10\n",
      "4           CatBoost_BAG_L2_FULL       0.984893   0.983658          f1        1.011818            NaN  46.175664                 0.023777                     NaN          11.316521            2       True         11\n",
      "5     ExtraTreesEntr_BAG_L1_FULL       0.984140   0.981904          f1        0.194169       0.753888   1.167090                 0.194169                0.753888           1.167090            1       True          7\n",
      "6       WeightedEnsemble_L2_FULL       0.983928   0.983060          f1        0.914618            NaN   7.252750                 0.014776                     NaN           1.440051            2       True          8\n",
      "7   RandomForestGini_BAG_L1_FULL       0.983702   0.982449          f1        0.216197       1.156748   1.215419                 0.216197                1.156748           1.215419            1       True          3\n",
      "8     ExtraTreesGini_BAG_L1_FULL       0.983312   0.982442          f1        0.193487       0.617617   1.338445                 0.193487                0.617617           1.338445            1       True          6\n",
      "9   RandomForestEntr_BAG_L1_FULL       0.983306   0.982063          f1        0.240852       0.646329   1.270684                 0.240852                0.646329           1.270684            1       True          4\n",
      "10      WeightedEnsemble_L3_FULL       0.983037   0.984329          f1        1.385620            NaN  41.141546                 0.015081                     NaN           2.009985            3       True         14\n",
      "11        LightGBMXT_BAG_L1_FULL       0.978465   0.976640          f1        0.074922            NaN   1.580093                 0.074922                     NaN           1.580093            1       True          1\n",
      "12          LightGBM_BAG_L1_FULL       0.977648   0.977566          f1        0.055138            NaN   0.821062                 0.055138                     NaN           0.821062            1       True          2\n",
      "13          CatBoost_BAG_L1_FULL       0.967823   0.971866          f1        0.013277            NaN  27.466351                 0.013277                     NaN          27.466351            1       True          5\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t278s\t = DyStack   runtime |\t622s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 622s\n",
      "AutoGluon will save models to \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\"\n",
      "Train Data Rows:    25578\n",
      "Train Data Columns: 12\n",
      "Label Column:       label\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = true, class 0 = false\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (true) vs negative (false) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1485.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.98 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['B6', 'B7']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', []) : 10 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 10 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 621.55s of the 621.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.33%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001B[36mray::_ray_fit()\u001B[39m (pid=23680, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001B[36mray::_ray_fit()\u001B[39m (pid=23680, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 615.17s of the 615.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.38%)\n",
      "2025-03-24 19:54:00,558\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=17824, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,563\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=34508, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,570\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=33724, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,574\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=38364, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,579\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=26520, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,584\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001B[36mray::_ray_fit()\u001B[39m (pid=18632, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\", line 283, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py\", line 134, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 317, in train\n",
      "    cb(\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 255, in _callback\n",
      "    _mem_early_stop()\n",
      "  File \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\.venv\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\callbacks.py\", line 162, in _mem_early_stop\n",
      "    % (best_iter[0] + 1, \"\\t\".join([_format_eval_result(x, show_stdv=False) for x in best_score_list[0]])),\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-03-24 19:54:00,587\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.981\t = Validation score   (f1)\n",
      "\t27.53s\t = Training   runtime\n",
      "\t2.21s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 581.23s of the 581.22s of remaining time.\n",
      "\t0.9837\t = Validation score   (f1)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 579.19s of the 579.18s of remaining time.\n",
      "\t0.9832\t = Validation score   (f1)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 577.13s of the 577.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.26%)\n",
      "\t0.9783\t = Validation score   (f1)\n",
      "\t462.09s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 110.83s of the 110.83s of remaining time.\n",
      "\t0.9831\t = Validation score   (f1)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 107.99s of the 107.98s of remaining time.\n",
      "\t0.983\t = Validation score   (f1)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 105.92s of the 105.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.20%)\n",
      "\t0.9778\t = Validation score   (f1)\n",
      "\t52.68s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 48.40s of the 48.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.21%)\n",
      "\t0.9825\t = Validation score   (f1)\n",
      "\t19.48s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 23.62s of the 23.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.11%)\n",
      "\t0.9665\t = Validation score   (f1)\n",
      "\t22.38s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -3.29s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L1': 0.583, 'ExtraTreesGini_BAG_L1': 0.125, 'CatBoost_BAG_L1': 0.083, 'ExtraTreesEntr_BAG_L1': 0.083, 'LightGBM_BAG_L1': 0.042, 'RandomForestEntr_BAG_L1': 0.042, 'XGBoost_BAG_L1': 0.042}\n",
      "\t0.9842\t = Validation score   (f1)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 628.03s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 922.0 rows/s (3198 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.14s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t191.15s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.87s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L1': 0.583, 'ExtraTreesGini_BAG_L1': 0.125, 'CatBoost_BAG_L1': 0.083, 'ExtraTreesEntr_BAG_L1': 0.083, 'LightGBM_BAG_L1': 0.042, 'RandomForestEntr_BAG_L1': 0.042, 'XGBoost_BAG_L1': 0.042}\n",
      "\t2.76s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 195.38s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9842\n",
      "\tBest Threshold: 0.579\t| val: 0.9851\n",
      "Updating predictor.decision_threshold from 0.5 -> 0.579\n",
      "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
      "\tPrediction probabilities of the positive class >0.579 will be predicted as the positive class (true). This can significantly impact metric scores.\n",
      "\tYou can update this value via `predictor.set_decision_threshold`.\n",
      "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n",
      "Deleting model LightGBM_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\LightGBM_BAG_L1 will be removed.\n",
      "Deleting model RandomForestGini_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\RandomForestGini_BAG_L1 will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\RandomForestEntr_BAG_L1 will be removed.\n",
      "Deleting model CatBoost_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\CatBoost_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\ExtraTreesGini_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\ExtraTreesEntr_BAG_L1 will be removed.\n",
      "Deleting model NeuralNetFastAI_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\NeuralNetFastAI_BAG_L1 will be removed.\n",
      "Deleting model XGBoost_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\XGBoost_BAG_L1 will be removed.\n",
      "Deleting model NeuralNetTorch_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\NeuralNetTorch_BAG_L1 will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\\models\\WeightedEnsemble_L2 will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\ei_ze_counter\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../models/ei/sample_combined_counter\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       2.29 GB / 15.35 GB (14.9%)\n",
      "Disk Space Avail:   553.07 GB / 731.50 GB (75.6%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "\t\tContext path: \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\ds_sub_fit\\sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ei_ze_counter:\n",
      "                          model  score_test score_val eval_metric  \\\n",
      "0      WeightedEnsemble_L2_FULL    0.986809      None          f1   \n",
      "1    ExtraTreesEntr_BAG_L1_FULL    0.986763      None          f1   \n",
      "2    ExtraTreesGini_BAG_L1_FULL    0.986548      None          f1   \n",
      "3  RandomForestGini_BAG_L1_FULL    0.986426      None          f1   \n",
      "4  RandomForestEntr_BAG_L1_FULL    0.985934      None          f1   \n",
      "5           XGBoost_BAG_L1_FULL    0.983768      None          f1   \n",
      "6          LightGBM_BAG_L1_FULL    0.981441      None          f1   \n",
      "7          CatBoost_BAG_L1_FULL    0.978723      None          f1   \n",
      "\n",
      "   pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0        1.266767            NaN  202.186594                 0.017528   \n",
      "1        0.224659       0.681959    1.163824                 0.224659   \n",
      "2        0.233698       0.784976    1.801519                 0.233698   \n",
      "3        0.210040       0.641834    1.152670                 0.210040   \n",
      "4        0.214853       0.685887    1.136765                 0.214853   \n",
      "5        0.125710            NaN    0.873995                 0.125710   \n",
      "6        0.189120            NaN    2.140112                 0.189120   \n",
      "7        0.051158            NaN  191.152770                 0.051158   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                     NaN           2.764940            2       True   \n",
      "1                0.681959           1.163824            1       True   \n",
      "2                0.784976           1.801519            1       True   \n",
      "3                0.641834           1.152670            1       True   \n",
      "4                0.685887           1.136765            1       True   \n",
      "5                     NaN           0.873995            1       True   \n",
      "6                     NaN           2.140112            1       True   \n",
      "7                     NaN         191.152770            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          8  \n",
      "1          6  \n",
      "2          5  \n",
      "3          2  \n",
      "4          3  \n",
      "5          7  \n",
      "6          1  \n",
      "7          4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2_FULL       0.980705   0.980182          f1        0.592708            NaN   6.544712                 0.004333                     NaN           1.382270            2       True          6\n",
      "1     ExtraTreesGini_BAG_L2_FULL       0.980599   0.981131          f1        0.868075            NaN  11.250058                 0.148804                0.755926           1.652681            2       True         12\n",
      "2     ExtraTreesEntr_BAG_L2_FULL       0.980591   0.981288          f1        0.858309            NaN  10.679852                 0.139038                0.694881           1.082475            2       True         13\n",
      "3         LightGBMXT_BAG_L2_FULL       0.980400   0.981046          f1        0.734928            NaN  10.027703                 0.015657                     NaN           0.430326            2       True          7\n",
      "4       WeightedEnsemble_L3_FULL       0.980194   0.981712          f1        1.178555            NaN  24.430301                 0.015919                     NaN           2.679657            3       True         14\n",
      "5   RandomForestEntr_BAG_L1_FULL       0.980055   0.979742          f1        0.212772       0.713050   1.110156                 0.212772                0.713050           1.110156            1       True          4\n",
      "6           CatBoost_BAG_L2_FULL       0.979979   0.980667          f1        0.727921            NaN  16.703799                 0.008650                     NaN           7.106422            2       True         11\n",
      "7   RandomForestGini_BAG_L1_FULL       0.979652   0.979712          f1        0.223557       0.748899   1.703435                 0.223557                0.748899           1.703435            1       True          3\n",
      "8   RandomForestEntr_BAG_L2_FULL       0.979549   0.981306          f1        0.840465            NaN  11.242323                 0.121194                0.641546           1.644947            2       True         10\n",
      "9   RandomForestGini_BAG_L2_FULL       0.979351   0.981118          f1        0.866393            NaN  11.303816                 0.147122                0.678465           1.706439            2       True          9\n",
      "10          LightGBM_BAG_L1_FULL       0.979036   0.975514          f1        0.152047            NaN   2.348851                 0.152047                     NaN           2.348851            1       True          2\n",
      "11          LightGBM_BAG_L2_FULL       0.978059   0.981266          f1        0.729293            NaN   9.833793                 0.010022                     NaN           0.236416            2       True          8\n",
      "12        LightGBMXT_BAG_L1_FULL       0.976920   0.974188          f1        0.122587            NaN   3.283212                 0.122587                     NaN           3.283212            1       True          1\n",
      "13          CatBoost_BAG_L1_FULL       0.896407   0.920176          f1        0.008308            NaN   1.151722                 0.008308                     NaN           1.151722            1       True          5\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t249s\t = DyStack   runtime |\t651s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 651s\n",
      "AutoGluon will save models to \"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\"\n",
      "Train Data Rows:    31688\n",
      "Train Data Columns: 12\n",
      "Label Column:       label\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = true, class 0 = false\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (true) vs negative (false) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3030.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 21.03 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['B6', 'B7']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', []) : 10 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 10 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.31 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 650.40s of the 650.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.19%)\n",
      "\t0.9761\t = Validation score   (f1)\n",
      "\t35.0s\t = Training   runtime\n",
      "\t2.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 610.50s of the 610.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
      "\t0.9781\t = Validation score   (f1)\n",
      "\t47.26s\t = Training   runtime\n",
      "\t4.66s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 557.73s of the 557.73s of remaining time.\n",
      "\t0.981\t = Validation score   (f1)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 555.62s of the 555.62s of remaining time.\n",
      "\t0.9808\t = Validation score   (f1)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 553.58s of the 553.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.25%)\n",
      "\t0.974\t = Validation score   (f1)\n",
      "\t442.95s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 106.78s of the 106.78s of remaining time.\n",
      "\t0.9809\t = Validation score   (f1)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 103.88s of the 103.88s of remaining time.\n",
      "\t0.9806\t = Validation score   (f1)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 101.49s of the 101.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.21%)\n",
      "\t0.9738\t = Validation score   (f1)\n",
      "\t73.27s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 24.04s of the 24.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.35%)\n",
      "\t0.9793\t = Validation score   (f1)\n",
      "\t19.29s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -0.13s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L1': 0.35, 'ExtraTreesGini_BAG_L1': 0.35, 'RandomForestGini_BAG_L1': 0.2, 'LightGBM_BAG_L1': 0.1}\n",
      "\t0.9815\t = Validation score   (f1)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 653.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 798.4 rows/s (3961 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.68s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L1': 0.35, 'ExtraTreesGini_BAG_L1': 0.35, 'RandomForestGini_BAG_L1': 0.2, 'LightGBM_BAG_L1': 0.1}\n",
      "\t2.39s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 3.56s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.9815\n",
      "\tBest Threshold: 0.576\t| val: 0.9819\n",
      "Updating predictor.decision_threshold from 0.5 -> 0.576\n",
      "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
      "\tPrediction probabilities of the positive class >0.576 will be predicted as the positive class (true). This can significantly impact metric scores.\n",
      "\tYou can update this value via `predictor.set_decision_threshold`.\n",
      "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n",
      "Deleting model LightGBMXT_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\LightGBMXT_BAG_L1 will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\LightGBM_BAG_L1 will be removed.\n",
      "Deleting model RandomForestGini_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\RandomForestGini_BAG_L1 will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\RandomForestEntr_BAG_L1 will be removed.\n",
      "Deleting model CatBoost_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\CatBoost_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\ExtraTreesGini_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\ExtraTreesEntr_BAG_L1 will be removed.\n",
      "Deleting model NeuralNetFastAI_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\NeuralNetFastAI_BAG_L1 will be removed.\n",
      "Deleting model XGBoost_BAG_L1. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\XGBoost_BAG_L1 will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\\models\\WeightedEnsemble_L2 will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"Z:\\Proyectos\\Data\\Data Science Projects\\genome-transition-auto-ml\\models\\ei\\sample_combined_counter\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for sample_combined_counter:\n",
      "                          model  score_test score_val eval_metric  \\\n",
      "0      WeightedEnsemble_L2_FULL    0.984326      None          f1   \n",
      "1  RandomForestGini_BAG_L1_FULL    0.983899      None          f1   \n",
      "2    ExtraTreesGini_BAG_L1_FULL    0.983835      None          f1   \n",
      "3  RandomForestEntr_BAG_L1_FULL    0.983624      None          f1   \n",
      "4          LightGBM_BAG_L1_FULL    0.981142      None          f1   \n",
      "\n",
      "   pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n",
      "0        1.085394            NaN  9.033000                 0.016394   \n",
      "1        0.219027       0.701526  1.214624                 0.219027   \n",
      "2        0.253825       0.916529  1.700583                 0.253825   \n",
      "3        0.233492       0.790707  1.042015                 0.233492   \n",
      "4        0.362656            NaN  2.683753                 0.362656   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                     NaN           2.392025            2       True   \n",
      "1                0.701526           1.214624            1       True   \n",
      "2                0.916529           1.700583            1       True   \n",
      "3                0.790707           1.042015            1       True   \n",
      "4                     NaN           2.683753            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          5  \n",
      "1          2  \n",
      "2          4  \n",
      "3          3  \n",
      "4          1  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "true_file = \"../data/ie/data_ie.csv\"\n",
    "ie_true_data = pd.read_csv(true_file)\n",
    "\n",
    "# List of counter example files for the EI zone\n",
    "counter_files = {\n",
    "    \"ie_random\": \"../data/ie/data_ie_random.csv\",\n",
    "    \"ie_ez_counter\": \"../data/ie/data_ez_counter_example.csv\",\n",
    "    \"ie_ei_true_counter\": \"../data/ie/data_ei_true_counter_example.csv\",\n",
    "    \"ie_ei_counter\": \"../data/ie/data_ei_counter_example.csv\",\n",
    "    \"ie_ze_counter\": \"../data/ie/data_ze_counter_example.csv\",\n",
    "    \"sample_combined_counter\": \"../data/ie/data_sample_combined.csv\"\n",
    "}\n",
    "\n",
    "# For IE zone, our CSV files have columns B1 to B105.\n",
    "combined_data = prepare_data(ie_true_data, counter_files, max_index=105)\n",
    "\n",
    "# Dictionary to store the combined DataFrames and later model results\n",
    "generateModels(combined_data, 'ie', 105, time_limit=900)"
   ],
   "id": "16ef630f027dbbdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "true_file = \"../data/ez/data_ez.csv\"\n",
    "ez_true_data = pd.read_csv(true_file)\n",
    "\n",
    "# List of counter example files for the EI zone\n",
    "counter_files = {\n",
    "    \"ez_random\": \"../data/ez/data_ez_random.csv\",\n",
    "    \"ez_ei_counter\": \"../data/ez/data_ei_counter_example.csv\",\n",
    "    \"ez_ie_counter\": \"../data/ez/data_ie_counter_example.csv\",\n",
    "    \"ez_ze_counter\": \"../data/ez/data_ze_counter_example.csv\",\n",
    "    \"sample_combined_counter\": \"../data/ez/data_sample_combined.csv\"\n",
    "}\n",
    "\n",
    "# For EZ zone, our CSV files have columns B1 to B550.\n",
    "combined_data = prepare_data(ez_true_data, counter_files, max_index=550)\n",
    "\n",
    "# Dictionary to store the combined DataFrames and later model results\n",
    "generateModels(combined_data, 'ez', 550, time_limit=900)"
   ],
   "id": "afd161db397f19e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "true_file = \"../data/ze/data_ze.csv\"\n",
    "ze_true_data = pd.read_csv(true_file)\n",
    "\n",
    "# List of counter example files for the EI zone\n",
    "counter_files = {\n",
    "    \"ze_random\": \"../data/ze/data_ze_random.csv\",\n",
    "    \"ze_ez_counter\": \"../data/ze/data_ez_counter_example.csv\",\n",
    "    \"ze_ie_counter\": \"../data/ze/data_ie_counter_example.csv\",\n",
    "    \"ze_ei_counter\": \"../data/ze/data_ei_counter_example.csv\",\n",
    "    \"sample_combined_counter\": \"../data/ze/data_sample_combined.csv\"\n",
    "}\n",
    "\n",
    "# For EZ zone, our CSV files have columns B1 to B550.\n",
    "combined_data = prepare_data(ze_true_data, counter_files, max_index=550)\n",
    "\n",
    "# Dictionary to store the combined DataFrames and later model results\n",
    "generateModels(combined_data, 'ze', 550, time_limit=900)"
   ],
   "id": "c9bf13ad02b3d5c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
